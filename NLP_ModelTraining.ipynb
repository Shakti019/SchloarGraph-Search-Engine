{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mount Google Drive\n",
    "Mounts Google Drive to access the processed Natural Language Processing (NLP) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32760,
     "status": "ok",
     "timestamp": 1766592246881,
     "user": {
      "displayName": "Shakti Singh",
      "userId": "15110137530207228295"
     },
     "user_tz": -330
    },
    "id": "4wYMuXcEF523",
    "outputId": "c32a666f-7492-45d4-c744-298627b271db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Qdrant Client\n",
    "Initializes the connection to the Qdrant Cloud vector database. This client will be used to create the `nlp_collection` and upload vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2188,
     "status": "ok",
     "timestamp": 1766592306189,
     "user": {
      "displayName": "Shakti Singh",
      "userId": "15110137530207228295"
     },
     "user_tz": -330
    },
    "id": "ELMYWmv0GrtL"
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as rest\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "     url=\"Enter your api URL***\",\n",
    "     api_key=\"Enter your Api key***\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspect Processed Data\n",
    "Reads and prints the first line of the processed NLP dataset (`nlp.jsonl`) to verify the data format before indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1766592342369,
     "user": {
      "displayName": "Shakti Singh",
      "userId": "15110137530207228295"
     },
     "user_tz": -330
    },
    "id": "2F59LL9CG27P",
    "outputId": "bd7e8e31-0b68-4d67-b736-4dd873c8913f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openalex_id': 'https://openalex.org/W2626778328', 'doi': 'https://doi.org/10.65215/ne77pf66', 'title': 'Attention Is All You Need', 'publication_year': 2025, 'publication_date': '2025-08-23', 'authors': [{'author_id': 'https://openalex.org/A5103024730', 'name': 'Ashish Vaswani'}, {'author_id': 'https://openalex.org/A5021878400', 'name': 'Noam Shazeer'}, {'author_id': 'https://openalex.org/A5005777963', 'name': 'Niki Parmar'}, {'author_id': 'https://openalex.org/A5022416424', 'name': 'Jakob Uszkoreit'}, {'author_id': 'https://openalex.org/A5023448834', 'name': 'Llion Jones'}, {'author_id': 'https://openalex.org/A5079288315', 'name': 'Aidan N. Gomez'}, {'author_id': 'https://openalex.org/A5031789995', 'name': '≈Åukasz Kaiser'}, {'author_id': 'https://openalex.org/A5045719436', 'name': 'Illia Polosukhin'}], 'concepts': [{'id': 'https://openalex.org/C41008148', 'name': 'Computer science'}, {'id': 'https://openalex.org/C203005215', 'name': 'Machine translation'}, {'id': 'https://openalex.org/C66322947', 'name': 'Transformer'}, {'id': 'https://openalex.org/C622187', 'name': 'BLEU'}, {'id': 'https://openalex.org/C118505674', 'name': 'Encoder'}, {'id': 'https://openalex.org/C154945302', 'name': 'Artificial intelligence'}, {'id': 'https://openalex.org/C148047603', 'name': 'Parallelizable manifold'}, {'id': 'https://openalex.org/C186644900', 'name': 'Parsing'}, {'id': 'https://openalex.org/C137293760', 'name': 'Language model'}, {'id': 'https://openalex.org/C204321447', 'name': 'Natural language processing'}, {'id': 'https://openalex.org/C57273362', 'name': 'Decoding methods'}, {'id': 'https://openalex.org/C2780451532', 'name': 'Task (project management)'}, {'id': 'https://openalex.org/C81363708', 'name': 'Convolutional neural network'}, {'id': 'https://openalex.org/C28490314', 'name': 'Speech recognition'}, {'id': 'https://openalex.org/C119857082', 'name': 'Machine learning'}, {'id': 'https://openalex.org/C11413529', 'name': 'Algorithm'}, {'id': 'https://openalex.org/C165801399', 'name': 'Voltage'}, {'id': 'https://openalex.org/C121332964', 'name': 'Physics'}, {'id': 'https://openalex.org/C162324750', 'name': 'Economics'}, {'id': 'https://openalex.org/C187736073', 'name': 'Management'}, {'id': 'https://openalex.org/C62520636', 'name': 'Quantum mechanics'}, {'id': 'https://openalex.org/C111919701', 'name': 'Operating system'}], 'citation_count': 6466, 'is_open_access': True, 'oa_status': 'gold', 'url': 'https://openalex.org/W2626778328'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = \"/content/drive/MyDrive/OpenAlex_CS_2025_Data/processed/nlp.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(json.loads(line))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Full Indexing Pipeline (NLP Domain)\n",
    "This is the main ingestion script for the NLP domain:\n",
    "1.  **Config**: Sets the collection name (`nlp_collection`), batch size, and vector size.\n",
    "2.  **Setup**: Creates the Qdrant collection if it doesn't exist.\n",
    "3.  **Ingest**:\n",
    "    *   Reads the `nlp.jsonl` file.\n",
    "    *   Generates embeddings using `all-MiniLM-L6-v2`.\n",
    "    *   Constructs the payload with metadata.\n",
    "    *   Uploads points in batches to Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285240,
     "status": "ok",
     "timestamp": 1766593592153,
     "user": {
      "displayName": "Shakti Singh",
      "userId": "15110137530207228295"
     },
     "user_tz": -330
    },
    "id": "unT26vCbHCDY",
    "outputId": "7120cc13-6f06-4f41-b981-afa56601548e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing NLP Papers: 10611it [04:43, 37.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FULL NLP COLLECTION INDEXED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "COLLECTION = \"nlp_collection\"   # ‚úÖ NEW COLLECTION\n",
    "BATCH_SIZE = 64             # safer for cloud\n",
    "VECTOR_SIZE = 384\n",
    "\n",
    "# ---------------- MODEL -----------------\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ---------------- QDRANT ----------------\n",
    "client = QdrantClient(\n",
    "    url=\"Enter your api URL***\",\n",
    "     api_key=\"Enter your Api key***\"\n",
    "    timeout=60  # ‚úÖ IMPORTANT\n",
    ")\n",
    "\n",
    "# ---------------- COLLECTION SETUP ----------------\n",
    "if not client.collection_exists(COLLECTION):\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION,\n",
    "        vectors_config=VectorParams(\n",
    "            size=VECTOR_SIZE,\n",
    "            distance=Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ---------------- INGEST ----------------\n",
    "points = []\n",
    "idx = 0\n",
    "\n",
    "with open(\n",
    "    \"/content/drive/MyDrive/OpenAlex_CS_2025_Data/processed/nlp.jsonl\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as f:\n",
    "\n",
    "    for line in tqdm(f, desc=\"Indexing NLP Papers\"):\n",
    "        paper = json.loads(line)\n",
    "\n",
    "        text = f\"{paper.get('title','')} {paper.get('abstract','')}\".strip()\n",
    "        if len(text) < 30:\n",
    "            continue\n",
    "\n",
    "        vector = model.encode(text).tolist()\n",
    "\n",
    "        payload = {\n",
    "            \"openalex_id\": paper.get(\"openalex_id\"),\n",
    "            \"doi\": paper.get(\"doi\"),\n",
    "            \"title\": paper.get(\"title\"),\n",
    "            \"abstract\": paper.get(\"abstract\"),\n",
    "            \"publication_year\": paper.get(\"publication_year\"),\n",
    "            \"publication_date\": paper.get(\"publication_date\"),\n",
    "            \"venue\": paper.get(\"venue\"),\n",
    "            \"citation_count\": paper.get(\"citation_count\"),\n",
    "            \"is_open_access\": paper.get(\"is_open_access\"),\n",
    "            \"oa_status\": paper.get(\"oa_status\"),\n",
    "            \"url\": paper.get(\"url\"),\n",
    "\n",
    "            # üî• STRUCTURED FIELDS\n",
    "            \"authors\": [\n",
    "                {\n",
    "                    \"id\": a.get(\"author_id\"),\n",
    "                    \"name\": a.get(\"name\")\n",
    "                } for a in paper.get(\"authors\", [])\n",
    "            ],\n",
    "\n",
    "            \"concepts\": [\n",
    "                {\n",
    "                    \"id\": c.get(\"id\"),\n",
    "                    \"name\": c.get(\"name\")\n",
    "                } for c in paper.get(\"concepts\", [])\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=idx,\n",
    "                vector=vector,\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "        idx += 1\n",
    "\n",
    "        if len(points) == BATCH_SIZE:\n",
    "            client.upsert(\n",
    "                collection_name=COLLECTION,\n",
    "                points=points,\n",
    "                wait=False  # ‚úÖ avoids timeout\n",
    "            )\n",
    "            points = []\n",
    "\n",
    "# Final flush\n",
    "if points:\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION,\n",
    "        points=points,\n",
    "        wait=False\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ FULL NLP COLLECTION INDEXED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test Retrieval (NLP Domain)\n",
    "Performs a sanity check on the indexed `nlp_collection`:\n",
    "1.  Encodes a test query (\"What are the open research gaps in nlp?\").\n",
    "2.  Searches the collection for the top 5 nearest neighbors.\n",
    "3.  Prints the detailed results to verify retrieval quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1766593691023,
     "user": {
      "displayName": "Shakti Singh",
      "userId": "15110137530207228295"
     },
     "user_tz": -330
    },
    "id": "hhGxDhf7KeSa",
    "outputId": "391ce41c-b226-4de4-d14f-3056e95e6f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned points: 5\n",
      "\n",
      "--- Result 1 ---\n",
      "Score: 0.5685\n",
      "Title: The Technological Trajectory of Semantic Analysis: A Historical-Methodological Review of NLP in Social Sciences\n",
      "DOI: https://doi.org/10.2139/ssrn.5022988\n",
      "Year: 2025\n",
      "Venue: SSRN Electronic Journal\n",
      "Citations: 1\n",
      "Open Access: True | Status: green\n",
      "URL: https://openalex.org/W4406351227\n",
      "Abstract: ‚ùå Not available\n",
      "Authors: Rodrigo Kataishi\n",
      "Concepts: Trajectory, Natural language processing, Semantic analysis (machine learning), Computer science, Artificial intelligence, Sentiment analysis\n",
      "\n",
      "--- Result 2 ---\n",
      "Score: 0.5509\n",
      "Title: Bridging language gaps: The role of NLP and speech recognition in oral english instruction\n",
      "DOI: https://doi.org/10.1016/j.mex.2025.103359\n",
      "Year: 2025\n",
      "Venue: MethodsX\n",
      "Citations: 1\n",
      "Open Access: True | Status: gold\n",
      "URL: https://openalex.org/W4410176650\n",
      "Abstract: ‚ùå Not available\n",
      "Authors: Parul Dubey, Pushkar Dubey, Rohit Raja, Sapna Singh Kshatri\n",
      "Concepts: Bridging (networking), Natural language processing, Computer science, Artificial intelligence, Linguistics, Speech recognition\n",
      "\n",
      "--- Result 3 ---\n",
      "Score: 0.5345\n",
      "Title: Exploring the Future of Corpus Linguistics: Innovations in AI and Social Impact\n",
      "DOI: https://doi.org/10.6000/2818-3401.2025.03.01\n",
      "Year: 2025\n",
      "Venue: International journal of mass communication.\n",
      "Citations: 1\n",
      "Open Access: True | Status: diamond\n",
      "URL: https://openalex.org/W4408277590\n",
      "Abstract: ‚ùå Not available\n",
      "Authors: Ersilia Incelli\n",
      "Concepts: Corpus linguistics, Applied linguistics, Text corpus, Collocation (remote sensing), Linguistics, Quantitative linguistics\n",
      "\n",
      "--- Result 4 ---\n",
      "Score: 0.508\n",
      "Title: Natural Language Processing (NLP) in Artificial Intelligence\n",
      "DOI: https://doi.org/10.30574/wjarr.2025.25.1.0275\n",
      "Year: 2025\n",
      "Venue: World Journal of Advanced Research and Reviews\n",
      "Citations: 2\n",
      "Open Access: False | Status: closed\n",
      "URL: https://openalex.org/W4406906244\n",
      "Abstract: ‚ùå Not available\n",
      "Authors: Sateesh Kumar Rongali\n",
      "Concepts: Artificial intelligence, Natural language processing, Computer science\n",
      "\n",
      "--- Result 5 ---\n",
      "Score: 0.5032\n",
      "Title: Advancements in AI-Powered NLP Models: A Critical Analysis of ChatGPT and DeepSeek\n",
      "DOI: https://doi.org/10.2139/ssrn.5125445\n",
      "Year: 2025\n",
      "Venue: SSRN Electronic Journal\n",
      "Citations: 3\n",
      "Open Access: True | Status: green\n",
      "URL: https://openalex.org/W4407373749\n",
      "Abstract: ‚ùå Not available\n",
      "Authors: Smiju I.S, D R Adinath\n",
      "Concepts: Natural language processing, Artificial intelligence, Computer science\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=\"Enter your api URL***\",\n",
    "    api_key=\"Enter your Api key***\"\n",
    ")\n",
    "\n",
    "query = \"What are the open research gaps in nlp?\"\n",
    "vector = model.encode(query).tolist()\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name=\"nlp_collection\"  ,\n",
    "    query=vector,\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"Returned points: {len(results.points)}\")\n",
    "\n",
    "for i, hit in enumerate(results.points, start=1):\n",
    "    p = hit.payload\n",
    "\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(\"Score:\", round(hit.score, 4))\n",
    "    print(\"Title:\", p.get(\"title\"))\n",
    "    print(\"DOI:\", p.get(\"doi\"))\n",
    "    print(\"Year:\", p.get(\"publication_year\"))\n",
    "    print(\"Venue:\", p.get(\"venue\"))\n",
    "    print(\"Citations:\", p.get(\"citation_count\"))\n",
    "    print(\"Open Access:\", p.get(\"is_open_access\"), \"| Status:\", p.get(\"oa_status\"))\n",
    "    print(\"URL:\", p.get(\"url\"))\n",
    "\n",
    "    # ‚úÖ SAFE abstract handling\n",
    "    abstract = p.get(\"abstract\")\n",
    "    if abstract:\n",
    "        print(\"Abstract:\", abstract[:600])\n",
    "    else:\n",
    "        print(\"Abstract: ‚ùå Not available\")\n",
    "\n",
    "    # ‚úÖ Authors\n",
    "    authors = p.get(\"authors\", [])\n",
    "    if authors:\n",
    "        print(\"Authors:\", \", \".join(a[\"name\"] for a in authors[:5]))\n",
    "    else:\n",
    "        print(\"Authors: ‚ùå Not available\")\n",
    "\n",
    "    # ‚úÖ Concepts\n",
    "    concepts = p.get(\"concepts\", [])\n",
    "    if concepts:\n",
    "        print(\"Concepts:\", \", \".join(c[\"name\"] for c in concepts[:6]))\n",
    "    else:\n",
    "        print(\"Concepts: ‚ùå Not available\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMCp9KkMwKs5pehnH78ekC1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
